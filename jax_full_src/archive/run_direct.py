#!/usr/bin/env python
"""
Direct execution of training components
"""

print("JAX AlphaZero Training - Direct Execution")
print("="*60)

# 1. Test self-play
print("\n1. Testing Self-Play Generation...")
import sys
sys.path.insert(0, 'jax_full_src')
from vectorized_self_play import VectorizedSelfPlay, SelfPlayConfig
from vectorized_nn import BatchedNeuralNetwork

config = SelfPlayConfig(
    batch_size=16,
    num_vertices=6,
    k=3,
    mcts_simulations=25
)
nn = BatchedNeuralNetwork(num_vertices=6, hidden_dim=64)
sp = VectorizedSelfPlay(config, nn)

# Generate games
print("Generating 50 games...")
experiences = sp.play_games(50, verbose=True)
print(f"Generated {len(experiences)} games")
total_positions = sum(len(e) for e in experiences)
print(f"Total positions: {total_positions}")

# 2. Save experiences
print("\n2. Saving experiences...")
import pickle
import os
os.makedirs('experiments/direct_test', exist_ok=True)
with open('experiments/direct_test/experiences.pkl', 'wb') as f:
    # Flatten experiences
    flattened = []
    for game_exp in experiences:
        flattened.extend(game_exp)
    pickle.dump(flattened, f)
print(f"Saved {len(flattened)} experiences")

# 3. Training would go here
print("\n3. Training network...")
print("(Training with PyTorch requires format conversion)")

# 4. Show statistics
print("\n4. Performance Statistics:")
print(f"- Parallel batch size: {config.batch_size}")
print(f"- MCTS simulations: {config.mcts_simulations}")
print(f"- Average game length: {total_positions/len(experiences):.1f} moves")

print("\nâœ… Direct execution completed successfully!")
print("This demonstrates the core functionality works.")
print("\nFor full pipeline with training and evaluation:")
print("python jax_full_src/pipeline_vectorized.py")